<!doctype html>
<html lang="en" class="no-js">
<meta http-equiv="content-type" content="text/html;charset=utf-8" />

<head>
	<meta charset="utf-8">
	<!-- Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-MNSPB7PT9W"></script>
	<script>window.dataLayer = window.dataLayer || []; function gtag() { dataLayer.push(arguments); } gtag('js', new Date()); gtag('config', 'G-MNSPB7PT9W');</script>
	<! -- MS Clarity -->
		<script
			type="text/javascript">(function (c, l, a, r, i, t, y) { c[a] = c[a] || function () { (c[a].q = c[a].q || []).push(arguments) }; t = l.createElement(r); t.async = 1; t.src = "https://www.clarity.ms/tag/" + i; y = l.getElementsByTagName(r)[0]; y.parentNode.insertBefore(t, y); })(window, document, "clarity", "script", "csp4wivxo8");</script>
		<!-- Begin SEO -->
		<script src="assets/js/jquery-3.3.1.js"></script>
		<script> $(function () { $("#header").load("header.html"); $("#sidebar").load("sidebar.html"); $("#footer").load("footer.html"); });</script>
		<meta property="og:locale" content="en-US">
		<meta property="og:site_name" content="Shubham's Webpage">
		<meta property="og:title" content="Experience">
		<link rel="canonical" href="experience.html">
		<meta property="og:url" content="experience.html">
		<meta property="og:description" content="Shubham Krishna Work Experience">
		<script type="application/ld+json"> { "@context" : "http://schema.org", "@type" : "Person", "name" : "Shubham Krishna", "url" : "https://shub-kris.github.io", "sameAs" : null }
	</script>
		<!-- End SEO -->
		<meta name="HandheldFriendly" content="True">
		<meta name="MobileOptimized" content="320">
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		<meta http-equiv="cleartype" content="on">
		<script> document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js '; </script>
		<link rel="stylesheet" href="assets/css/main.css">
		<link rel="stylesheet" href="assets/css/main.bundle.css">
		<meta http-equiv="cleartype" content="on">
		<!-- Start custom head snippets -->
		<title>Shubham Krishna | Experience</title>
</head>

<body>
	<div id="header"></div>
	<div id="main" role="main">
		<div id="sidebar"></div>
		<div class="archive">
			<h2 style="font-size: x-large;"><b>Work Experience</b></h2>
			<div class="list__item" style="margin-top: 2%;">
				<div class="card">
					<div class="card-content">
						<div class="media">
							<div class="media-left">
								<figure class="image is-48x48">
									<img src="images/experiences/ml6.png" alt="ML6">
								</figure>
							</div>
							<div class="media-content">
								<p class="title is-4">ML6</p>
								<p class="subtitle is-6">Machine Learning Engineer, ML in Production, Berlin |
									<time datetime="2021-12">Dec 2021</time> - <time datetime="2022-7"> Now</time>
								</p>
							</div>
						</div>
						<div class="content">
							<p>Generative AI, Computer Vision, NLP</p>
							<ul>
								<li>Finetuned Text2Img and Image Variations Stable Diffusion models for generating
									stickers, print designs and artistic inspirations. Deployed it as a scalable service
									on AWS EC2 instance
									and models are integrated into the company’s e-commerce platform, allowing users to
									generate custom artistic
									images using text and image prompts.
									[<a href="https://www.creativefabrica.com/spark/tools/art-generator/"
										style="color:#52adc8"><strong>Text2Img Model Link</strong></a>, <a
										href="https://www.creativefabrica.com/spark/tools/imagemix/"
										style="color:#52adc8"><strong>Image Variations Model Link
										</strong></a>]
								</li>
								<li>Finetuned a deep learning model (<a
										href="https://xuebinqin.github.io/dis/index.html"
										style="color:#52adc8"><strong>ISNet</strong></a>) for removing solid background
									from
									images generated using Stable Diffusion models. Used as a postprocessing step and
									helps in creation of images with transparent background.
								<li>More than 3 million images were generated in the first month. [<a
										href="https://techcrunch.com/2022/10/31/digital-assets-marketplace-creative-fabrica-launches-generative-ai-tool/?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAAG1tb_34fvnJfcwS5r-nIbs-6OSBUpXXlDdegyBfojrAXuq3qN-y5s2c_zEt0K_n9zkvGOOR0vu3VPUft6KXxuv89UirG70SQbaDbkhW1uMx90Xs9LV9O-QRxdthM7TjZ4BK88B13wiZ1hsiNGgjbuJz8vp-HQdWYhho3V3JBWkj"
										style="color:#52adc8"><strong>
											TechCrunch Article Link </strong></a>]</li>
							</ul>
							<div class="tags">
								<span class="tag">Python</span>
								<span class="tag">PyTorch</span>
								<span class="tag">HuggingFace Diffusers</span>
								<span class="tag">AWS</span>
								<span class="tag">Fast API</span>
								<span class="tag">Pillow</span>
							</div>
							<p>Recommender System, MLOps, Data Engineering</p>
							<ul>
								<li>Developed highly scalable, automated, and robust ETL pipelines for the ingestion
									of large volumes of catalog
									(more than 100k) and user events (more than 1.2 million) data everyday using Apache
									Beam from client’s FTP
									server to Google Cloud Retail API storage. </li>
								<li>Utilized established pipelines to build and deploy recommendation models: Similar
									Items and Frequently
									Bought Together using Google Cloud Retail API for a retail company’s e-commerce
									platform, resulting in a
									<strong>300k Euros/week</strong> revenue increase due to a <strong>40%
										increase</strong> in
									conversion rate.
								</li>
								<li>
									Utilized Terraform and GitHub Actions to setup the infrastructure required for
									developing the functionality.
								</li>
							</ul>
							<div class="tags">
								<span class="tag">Python</span>
								<span class="tag">Apache Beam</span>
								<span class="tag">Google Cloud</span>
								<span class="tag">GitHub Actions</span>
								<span class="tag">Terraform</span>
								<span class="tag">CI/CD</span>
							</div>
							<p>MLOps, NLP</p>
							<ul>
								<li>Developed multiple scalable machine learning pipelines for efficient and accurate
									inference using Apache Beam
									RunInference API.
								</li>
								<li> Utilized different machine/deep learning models available in
									PyTorch, Tensorflow, and Scikit-Learn to illustrate how one can use Apache Beam for
									building machine learning pipelines.
								</li>
								<li>
									Some of the pipelines are: <a
										href="https://beam.apache.org/documentation/ml/large-language-modeling/"
										style="color:#52adc8"><strong>
											Large Language Model
											Inference in Beam </strong></a>,
									<a href="https://beam.apache.org/documentation/ml/tensorrt-runinference/"
										style="color:#52adc8"><strong>
											Using TensorRT with Beam </strong></a>,
									and <a href="https://beam.apache.org/documentation/ml/per-entity-training/"
										style="color:#52adc8"><strong>
											Per Entity Training in Beam </strong></a>. The pipelines were
									contributed to Apache Beam and
									are available as examples in the <a
										href="https://beam.apache.org/documentation/ml/overview/"
										style="color:#52adc8"><strong>
											Apache Beam documentation </strong></a>.
								</li>
							</ul>
							<div class="tags">
								<span class="tag">Python</span>
								<span class="tag">Apache Beam</span>
								<span class="tag">Google Cloud</span>
								<span class="tag">PyTorch</span>
								<span class="tag">TensorFlow</span>
								<span class="tag">HuggingFace Transformers</span>
								<span class="tag">NVIDIA Triton</span>

							</div>
							<p>MLOps, Computer Vision, NLP</p>
							<ul>
								<li>Developed multiple end-to-end GCP Vertex AI based ML pipelines for tasks
									including text-classification, semantic
									segmentation, and others, easily adaptable to other machine learning tasks. </li>
								<li>The generic pipeline has been presented
									at industry meetups and
									utilized in multiple projects.
								</li>
							</ul>
							<div class="tags">
								<span class="tag">Python</span>
								<span class="tag">PyTorch</span>
								<span class="tag">Vertex AI</span>
								<span class="tag">KubeFlow</span>
								<span class="tag">Google Cloud</span>
								<span class="tag">HuggingFace Transformers</span>
								<span class="tag">CI/CD</span>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="list__item" style="margin-top: 2%;">
				<div class="card">
					<div class="card-content">
						<div class="media">
							<div class="media-left">
								<figure class="image is-48x48">
									<img src="images/experiences/bosch.png" alt="Bosch">
								</figure>
							</div>
							<div class="media-content">
								<p class="title is-4">Bosch Center for Artificial Intelligence</p>
								<p class="subtitle is-6">Master Thesis, Robust Deep Learning, Renningen, Germany |
									<time datetime="2021-5">May 2021</time> - <time datetime="2021-11">Nov 2021</time>
								</p>
							</div>
						</div>
						<div class="content">
							<p>Master Thesis, Computer Vision</p>
							<ul>
								<li>Tackled the problem of Label Noise in
									Semantic Segmentation. Developed a two stage generic framework for
									reducing amount of noise using semi-supervised
									learning. The proposed framework can be easily
									extended to deal with label noise for other
									computer vision tasks such as object detection and instance segmentation.</li>
								<li>The framework reduced the noise from 100% to 33.33% and therefore helped in
									improving the mean Intersection over
									Union (mIoU) by 9% on
									corrupted CityScapes validation dataset.
								</li>
								<li>Discovered that
									both discarding and pseudo-labeling noisy pixels are effective strategies for
									dealing
									with asymmetric label noise. As a result of experiments, discovered that
									semi-supervised learning is more robust to noise compared to supervised learning
								</li>
							</ul>
							<div class="tags">
								<span class="tag">Python</span>
								<span class="tag">PyTorch</span>
								<span class="tag">Matplotlib</span>
								<span class="tag">NumPy</span>
								<span class="tag">Pandas</span>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="list__item" style="margin-top: 2%;">
				<div class="card">
					<div class="card-content">
						<div class="media">
							<div class="media-left">
								<figure class="image is-48x48">
									<img src="images/experiences/max_planck_institute.jpeg" alt="MPI">
								</figure>
							</div>
							<div class="media-content">
								<p class="title is-4">Max Planck Institute for Intelligent Systems</p>
								<p class="subtitle is-6">Research Assistant, <a href="https://bethgelab.org/"
										style="color:#52adc8">Bethge Lab
									</a>, Tübingen, Germany |
									<time datetime="2021-4">Apr 2020</time> - <time datetime="2021-10">Oct 2021</time>
								</p>
							</div>
						</div>
						<div class="content">
							<p>Deep Learning, Computer Vision</p>
							<ul>
								<li>Worked on multiple projects in the field of computer vision, with a particular focus
									on topics such as invariant
									representation learning and pruning to make neural networks
									more efficient, and
									faster.</li>
								<li>Contributed to project ideation
									and hypothesis
									development, as well as developing
									robust codebases to validate research findings. </li>
								<li>Proposed Generalized Invariant Risk Minimization (GIRM) [<a
										href="https://preregister.science/papers_20neurips/57_paper.pdf"
										style="color:#52adc8"><strong>NeurIPS Workshop Paper Link</strong></a>], a
									technique that takes a pre-specified adaptation mechanism and aims to find invariant
									representations that (a) perform well across multiple different training
									environments
									and (b) cannot be improved through adaptation to individual environments.</li>
								<li>Worked with <a href="https://stes.io/" style="color:#52adc8">Steffen Schneider
									</a>
									under the guidance of <a href="https://is.mpg.de/person/wbrendel"
										style="color:#52adc8">Wieland Brendel
									</a>and
									<a href="https://bethgelab.org/people/" style="color:#52adc8">Matthias Bethge
									</a>.
								</li>
							</ul>
							<div class="tags">
								<span class="tag">Python</span>
								<span class="tag">PyTorch</span>
								<span class="tag">PyTorch Lightning</span>
								<span class="tag">Matplotlib</span>
								<span class="tag">Docker</span>
								<span class="tag">Slurm</span>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="list__item" style="margin-top: 2%">
				<div class="card">
					<div class="card-content">
						<div class="media">
							<div class="media-left">
								<figure class="image is-48x48">
									<img src="images/experiences/samsung.svg" alt="Samsung">
								</figure>
							</div>
							<div class="media-content">
								<p class="title is-4">Samsung Research</p>
								<p class="subtitle is-6">AppliedResearch Engineer,On Device AI,
									Bangalore |
									<time datetime="2018-06">Jun 2018</time> - <time datetime="2019-9">Sep 2019</time>
								</p>
							</div>
						</div>
						<div class="content">
							<p>Information Retrieval, Deep Learning, NLP</p>
							<ul>
								<li>Developed a sophisticated deep learning-based model for keyword extraction,
									utilizing application descriptions from
									AppStore. Successfully <strong>commercialized</strong> the model for Samsung's
									flagship smartphones,
									where it was triggered daily to
									generate keywords for newly developed apps.
								</li>
								<li>
									The search index stored the extracted keywords, which led to a significant
									<strong>25% increase</strong>
									in recall for application search
									on mobile devices. e.g. Keywords for Uber Eats are Food, Delivery, Order, Restaurant
									and others.
								</li>
								<li>
									The project involved designing and training the model, optimizing its performance
									through continuous experimentation,
									and integrating it with the Samsung Search app.
								</li>
								<li>
									Published two research papers showcasing innovative approaches in the field.
									Presented a novel method for app
									clustering, classification, and retrieval using app-embeddings at CICLing 2019,
									resulting in improved end-user
									experience with mobile apps. Also, published a paper at NLDB 2019 on a multi-task
									neural architecture that predicts
									categorical parameters like app category and ratings by jointly modeling app
									descriptions and reviews.
								</li>
							</ul>
							<div class="tags">
								<span class="tag">Python</span>
								<span class="tag">TensorFlow</span>
								<span class="tag">Keras</span>
								<span class="tag">NLTK</span>
								<span class="tag">Spacy</span>
								<span class="tag">Java</span>
							</div>
							<p>Information Retrieval, Machine Learning, NLP</p>
							<ul>
								<li>Developed and integrated a machine learning model using Apache OpenNLP for Name
									Entity Recognition and Stanford Core NLP
									for processing temporal expressions within the Gallery App, enabling natural
									language query search (e.g. Photos of me and Nikhil from last year in Paris)
									functionality.
								</li>
								<li>
									Through rigorous experimentation and optimization, successfully delivered a feature
									that enhances the user experience
									and revolutionizes the way users search for their desired images.
								</li>
								<li>
									Awarded the Best Demo prize at Samsung’s Annual Technical Event for the Proof of
									Concept feature developed within the
									Gallery App.
								</li>
							</ul>
							<div class="tags">
								<span class="tag">Python</span>
								<span class="tag">Apache OpenNLP</span>
								<span class="tag">Stanford CoreNLP</span>
								<span class="tag">NLTK</span>
								<span class="tag">Spacy</span>
								<span class="tag">Java</span>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="list__item" style="margin-top: 2%">
				<div class="card">
					<div class="card-content">
						<div class="media">
							<div class="media-left">
								<figure class="image is-48x48">
									<img src="images/experiences/samsung.svg" alt="Samsung">
								</figure>
							</div>
							<div class="media-content">
								<p class="title is-4">Samsung Research</p>
								<p class="subtitle is-6">Deep Learning Intern, Voice Assistant Team,
									Bangalore |
									<time datetime="2017-5">May 2017</time> - <time datetime="2020-7">July 2017</time>
								</p>
							</div>
						</div>
						<div class="content">
							<p>Deep Learning, NLP, Text Classification</p>
							<ul>
								<li> Designed and implemented a Proof of Concept (POC) text classification model for
									detecting hate speech using LSTM and
									Word2Vec embeddings.</li>
								<li> The developed model resulted in a 15%
									increase in the F1 score for hate
									speech detection compared to the baseline, paving the way for improved
									decision-making capabilities in a variety of applications.</li>
								<li>The developed model was then deployed into an App using TFLite for demo purposes.
									The deployment process involved optimizing the model for mobile devices and ensuring
									its compatibility with the app's
									existing infrastructure.
								</li>
							</ul>
							<div class="tags">
								<span class="tag">Python</span>
								<span class="tag">TensorFlow</span>
								<span class="tag">Keras</span>
								<span class="tag">NLTK</span>
								<span class="tag">Spacy</span>
								<span class="tag">Scikit-Learn</span>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="list__item" style="margin-top: 2%">
				<div class="card">
					<div class="card-content">
						<div class="media">
							<div class="media-left">
								<figure class="image is-48x48">
									<img src="images/experiences/imt_atlantique.svg" alt="IMT">
								</figure>
							</div>
							<div class="media-content">
								<p class="title is-4">IMT Atlantique, France</p>
								<p class="subtitle is-6">Research Intern, LUSSI Lab |
									<time datetime="2018-1">Jan 2018</time> - <time datetime="2018-4">Apr 2018</time>
								</p>
							</div>
						</div>
						<div class="content">
							<p>Machine Learning, Unsupervised Learning, Clustering</p>
							<ul>
								<li>Conducted an end-to-end machine learning project under the guidance of Nicolas
									Jullien and Romain Billot
									aimed at identifying common behavior among online contributors of Wikipedia.</li>
								<li>Performed a large-scale study on the contributing pattern of Wikipedia's online
									contributors utilizing different
									clustering algorithms and Principle Component Analysis using hand-engineered
									features, such as frequency of contributions and time gaps between contributions.
								</li>
								<li>Utilized ANOVA and Students t-test for examining statistically significant
									differences among different clusters
									, leading to a poster
									presentation in the OpenSym 2018, the 14th
									International Symposium on Open Collaboration.
								</li>
							</ul>
							<div class="tags">
								<span class="tag">Python</span>
								<span class="tag">Numpy</span>
								<span class="tag">Scikit-Learn</span>
								<span class="tag">Matplotlib</span>
							</div>
						</div>
					</div>
				</div>
			</div>
		</div>
	</div>
	<br><br><br><br><br>
	<div id="footer"></div>
</body>

</html>